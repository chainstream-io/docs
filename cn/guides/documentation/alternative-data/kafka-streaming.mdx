---
title: 'Kafka 流处理'
description: '实时区块链数据的 Kafka 流处理实现指南'
---

## Kafka 优势

<CardGroup cols={3}>
  <Card title="更低延迟" icon="bolt">
    - 更短的数据管道
    - 与 GraphQL 订阅相比处理开销更小
    - 无需自定义数据库或额外的格式化逻辑
  </Card>
  
  <Card title="更好的可靠性" icon="shield-check">
    - 比 WebSocket 更稳定的连接协议
    - 针对持久连接优化
    - 可以从最新偏移量读取消息
  </Card>
  
  <Card title="更强的可扩展性" icon="arrows-up-down-left-right">
    - 多个消费者可以分担负载
    - 自动负载重分配
    - 更好地处理高容量数据
  </Card>
</CardGroup>

## Kafka 限制

<CardGroup cols={3}>
  <Card title="浏览器不兼容" icon="browser">
    - 仅支持服务器端实现
    - 无法直接在浏览器中使用
  </Card>
  
  <Card title="有限的过滤功能" icon="filter">
    - 无预过滤功能
    - 预定义的模式
    - 需要客户端后处理
  </Card>
  
  <Card title="开发复杂性" icon="code">
    - 无 IDE 对流的支持
    - 调试仅限于消费者端
  </Card>
</CardGroup>

## 技术考虑因素

<Note>
  使用 Kafka 流时，需要考虑消息保留策略、延迟影响和分区策略。关键数据流的消息默认保留 24 小时。
</Note>

## 实现指南

### 消息保留

<Card title="保留策略" icon="clock">
  - Protobuf 流：保留 24 小时
  - DEX 交易（JSON）：保留 24 小时
  - 其他 JSON 流：保留 4 小时
</Card>

### 连接设置

<CodeGroup>
  ```javascript Configuration
  const sasl_conf = {
    'bootstrap.servers': 'kfk0.chainstream.io:9093,kfk1.chainstream.io:9093,kfk2.chainstream.io:9093',
    'security.protocol': 'SASL_SSL',
    'sasl.mechanism': 'SCRAM-SHA-512',
    'sasl.username': '<YOUR USERNAME>',
    'sasl.password': '<YOUR PASSWORD>',
    'ssl.key.location': 'client.key.pem',
    'ssl.ca.location': 'server.cer.pem',
    'ssl.certificate.location': 'client.cer.pem',
    'ssl.endpoint.identification.algorithm': 'none'
  }
  ```
</CodeGroup>

### 主题结构

<CodeGroup>
  ```plaintext Topic Format
  <BLOCKCHAIN_NAME>.<MESSAGE_TYPE>
  <BLOCKCHAIN_NAME>.broadcasted.<MESSAGE_TYPE>
  ```
</CodeGroup>

<div className="mt-6">
消息类型：

- `dextrades` - DEX 交易
- `dexorders` - DEX 订单
- `dexpools` - DEX 池
- `transactions` - 交易
- `transfers` - 转账
- `instructions` - 指令
- `raw` - 原始数据
</div>

## Kafka 流处理最佳实践

<Card title="高吞吐量的并行处理" icon="layer-group">
  <div className="mt-2">
    - 在多个分区之间分配消费者以并行处理数据
    - 为每个分区分配一个消费者线程以实现高效的负载均衡
  </div>
</Card>

<Card title="持续流处理以保持稳定性" icon="infinity">
  <div className="mt-2">
    - 保持 Kafka 消费者运行以确保数据流的无缝衔接
    - 异步处理消息以防止瓶颈
    - 避免阻塞主消费循环以维持最佳吞吐量
  </div>
</Card>

<Card title="优化的消息处理" icon="gears">
  <div className="mt-2">
    - 在适用的情况下实现批处理以减少开销
    - 使用工作组以提高并发性
    - 持续监控处理延迟以确保实时性能
  </div>
</Card>

## 其他代码示例

### 前提条件

<CardGroup cols={2}>
  <Card title="ChainStream Kafka 服务器访问" icon="server">
    访问 ChainStream Kafka 代理
  </Card>
  <Card title="认证凭据" icon="key">
    Kafka 代理的用户名和密码
  </Card>
  <Card title="主题订阅" icon="list">
    要订阅的主题名称
  </Card>
  <Card title="Go 安装" icon="golang">
    Go 版本 >= 1.16
  </Card>
  <Card title="Kafka 客户端" icon="plug">
    Confluent Kafka Go 客户端库
  </Card>
</CardGroup>

### 依赖设置

<CodeGroup>
  ```bash Go Module Init
  go mod init kafka-consumer
  ```

  ```bash Install Kafka Client
  go get github.com/confluentinc/confluent-kafka-go/kafka
  ```
</CodeGroup>

### 实现

<AccordionGroup>
  <Accordion title="Kafka 客户端初始化" icon="gear" defaultOpen={true}>
    ```go
    config := &kafka.ConfigMap{
        "bootstrap.servers":                     "rpk0.chainstream.io:9093,rpk1.chainstream.io:9093,rpk2.chainstream.io:9093",
        "group.id":                              "solanatest2-group-99",
        "session.timeout.ms":                    30000,
        "security.protocol":                     "SASL_SSL",
        "ssl.ca.location":                       "server.cer.pem",
        "ssl.key.location":                      "client.key.pem",
        "ssl.certificate.location":              "client.cer.pem",
        "ssl.endpoint.identification.algorithm": "none",
        "sasl.mechanisms":                       "SCRAM-SHA-512",
        "sasl.username":                         "usernamee",
        "sasl.password":                         "pwww",
        "auto.offset.reset":                     "latest",
    }
    ```
  </Accordion>

  <Accordion title="Kafka 消费者设置" icon="play" defaultOpen={true}>
    ```go
    consumer, err := kafka.NewConsumer(config)
    if err != nil {
        fmt.Printf("Failed to create consumer: %s\n", err)
        os.Exit(1)
    }

    topic := "solana.broadcasted.transactions"

    // 订阅主题
    err = consumer.SubscribeTopics([]string{topic}, nil)
    if err != nil {
        fmt.Printf("Failed to subscribe to topic: %s\n", err)
        os.Exit(1)
    }
    ```
  </Accordion>

  <Accordion title="消息处理循环" icon="rotate" defaultOpen={true}>
    ```go
    // 设置一个通道来处理关闭
    sigchan := make(chan os.Signal, 1)
    signal.Notify(sigchan, syscall.SIGINT, syscall.SIGTERM)

    // 轮询消息并处理它们
    run := true
    for run {
        select {
        case sig := <-sigchan:
            fmt.Printf("捕获信号 %v：终止中\n", sig)
            run = false
        default:
            ev := consumer.Poll(100)
            if ev == nil {
                continue
            }

            switch e := ev.(type) {
            case *kafka.Message:
                processMessage(e)

            case kafka.Error:
                fmt.Printf("错误：%v\n", e)
                if e.Code() == kafka.ErrAllBrokersDown {
                    run = false
                }
            default:
                fmt.Printf("已忽略 %v\n", e)
            }
        }
    }

    // 关闭消费者
    consumer.Close()
    ```
  </Accordion>

  <Accordion title="消息处理函数" icon="message-dots" defaultOpen={true}>
    ```go
    func processMessage(msg *kafka.Message) {
        fmt.Printf("在主题 %s [%d] 的偏移量 %v 处收到消息：\n",
            *msg.TopicPartition.Topic, msg.TopicPartition.Partition, msg.TopicPartition.Offset)

        // 尝试将消息值解析为 JSON
        var jsonData interface{}
        err := json.Unmarshal(msg.Value, &jsonData)
        if err != nil {
            fmt.Printf("Error parsing JSON: %v\n", err)
            fmt.Printf("Raw message: %s\n", string(msg.Value))
            return
        }

        // Pretty print the JSON
        prettyJSON, err := json.MarshalIndent(jsonData, "", "  ")
        if err != nil {
            fmt.Printf("Error prettifying JSON: %v\n", err)
            return
        }

        fmt.Printf("Parsed JSON:\n%s\n", string(prettyJSON))

        // Log message data
        logEntry := map[string]interface{}{
            "topic":     *msg.TopicPartition.Topic,
            "partition": msg.TopicPartition.Partition,
            "offset":    msg.TopicPartition.Offset,
            "key":       string(msg.Key),
            "value":     string(prettyJSON),
        }
        fmt.Printf("Log entry: %+v\n", logEntry)
        fmt.Println("----------------------------------------")
    }
    ```
  </Accordion>
</AccordionGroup>

### 运行应用程序

<CodeGroup>
  ```bash Initialize Go Module
  go mod init kafka-consumer
  ```

  ```bash Run Application
  go run consumer.go
  ```
</CodeGroup>

### 执行工作流

<CardGroup cols={2}>
  <Card title="Kafka 客户端初始化" icon="gear">
    - 使用 SSL 和 SASL 配置进行初始化
    - 设置唯一的 group.id 以实现独立的消息消费
  </Card>
  <Card title="消费者设置" icon="plug">
    - 创建 Kafka 消费者
    - 订阅指定主题
  </Card>
  <Card title="消息处理" icon="arrows-rotate">
    - 每 100ms 轮询新消息
    - 解析 JSON 消息
    - 记录处理后的数据
  </Card>
  <Card title="优雅关闭" icon="power-off">
    - 处理终止信号
    - 清理关闭消费者
  </Card>
</CardGroup> 